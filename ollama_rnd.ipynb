{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-16T08:13:11.397491Z",
     "start_time": "2025-03-16T08:13:10.198757Z"
    }
   },
   "source": "import ollama",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T09:17:40.528982Z",
     "start_time": "2025-03-16T09:17:40.523984Z"
    }
   },
   "cell_type": "code",
   "source": "print(dir(ollama))",
   "id": "cf28e8814dcb48e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AsyncClient', 'ChatResponse', 'Client', 'EmbedResponse', 'EmbeddingsResponse', 'GenerateResponse', 'Image', 'ListResponse', 'Message', 'Options', 'ProcessResponse', 'ProgressResponse', 'RequestError', 'ResponseError', 'ShowResponse', 'StatusResponse', 'Tool', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_client', '_types', '_utils', 'chat', 'copy', 'create', 'delete', 'embed', 'embeddings', 'generate', 'list', 'ps', 'pull', 'push', 'show']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T09:27:13.755824Z",
     "start_time": "2025-03-16T09:23:44.750286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = 'How can LLMs be used in engineering?'\n",
    "response = ollama.generate(model='gemma3:4b', prompt=question)\n",
    "print(response['response'])"
   ],
   "id": "4ede785336525e5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) are rapidly finding their way into various engineering disciplines, offering exciting possibilities for automation, efficiency, and innovation. Here's a breakdown of how they're being used, categorized by engineering field and function:\n",
      "\n",
      "**1. General Engineering Applications (Across Disciplines):**\n",
      "\n",
      "* **Documentation & Knowledge Management:**\n",
      "    * **Generating Technical Reports:** LLMs can draft initial drafts of reports, specifications, and proposals based on prompts and data.\n",
      "    * **Creating Standard Operating Procedures (SOPs):**  They can generate SOPs for equipment operation, maintenance, and troubleshooting.\n",
      "    * **Knowledge Base Creation & Retrieval:**  LLMs can synthesize information from vast amounts of technical documentation, research papers, and internal knowledge bases, making it easier to find relevant information.\n",
      "    * **Translation:**  Quickly translate technical documents between languages.\n",
      "* **Code Generation & Assistance:**\n",
      "    * **Generating Code Snippets:**  LLMs like Codex (now integrated into GitHub Copilot) can generate code in various languages (Python, C++, MATLAB, etc.) based on natural language descriptions of the desired functionality.\n",
      "    * **Debugging & Code Explanation:**  They can analyze code, identify potential bugs, and explain complex code logic.\n",
      "    * **Automated Unit Test Generation:**  LLMs can generate basic unit tests based on code functionality.\n",
      "* **Brainstorming & Design Exploration:**\n",
      "    * **Generating Design Ideas:**  Provide a problem description, and the LLM can suggest potential design solutions, materials, or approaches.\n",
      "    * **Exploring Design Trade-offs:**  Simulate the impact of different design choices on performance, cost, and other factors.\n",
      "* **Data Analysis & Interpretation:**\n",
      "    * **Generating Insights from Data:**  LLMs can analyze data sets and generate summaries, identify trends, and suggest potential correlations. (Often combined with other AI tools).\n",
      "\n",
      "\n",
      "**2. Specific Engineering Disciplines:**\n",
      "\n",
      "* **Mechanical Engineering:**\n",
      "    * **Finite Element Analysis (FEA) Prompting:**  LLMs can help generate prompts for FEA software, specifying boundary conditions, material properties, and desired analyses.\n",
      "    * **Design Optimization:**  Suggest design modifications to improve performance based on specified constraints.\n",
      "    * **Generating CAD Descriptions:**  Describe a mechanical component, and the LLM can generate a basic CAD model (still in early stages of development).\n",
      "* **Civil Engineering:**\n",
      "    * **Structural Analysis Support:**  Similar to mechanical engineering, LLMs can assist in generating prompts for structural analysis software.\n",
      "    * **Generating Construction Documents:**  Draft initial versions of drawings and specifications based on project requirements.\n",
      "    * **Risk Assessment:**  Analyze project data and identify potential risks.\n",
      "* **Electrical Engineering & Computer Engineering:**\n",
      "    * **Schematic Generation:**  Describe a circuit or system, and the LLM can generate a basic schematic diagram.\n",
      "    * **Hardware Description Language (HDL) Generation:**  Generate code for FPGAs and ASICs based on natural language descriptions.\n",
      "    * **System Design Documentation:**  Create detailed documentation for complex electronic systems.\n",
      "* **Chemical Engineering:**\n",
      "    * **Process Simulation Support:**  Generate prompts for process simulation software.\n",
      "    * **Reaction Engineering Calculations:**  Assist in calculating reaction rates and equilibrium constants.\n",
      "    * **Material Selection:**  Suggest appropriate materials based on process conditions and performance requirements.\n",
      "* **Aerospace Engineering:**\n",
      "    * **Flight Simulation Scripting:**  Generate scripts for flight simulators.\n",
      "    * **Design Optimization for Aircraft Components:**  Suggest design modifications to improve aerodynamic performance.\n",
      "    * **Generating Technical Reports on Aerodynamic Performance.**\n",
      "\n",
      "\n",
      "**3. Tools & Platforms Leveraging LLMs:**\n",
      "\n",
      "* **GitHub Copilot:**  A popular AI pair programmer that uses Codex (an LLM) to suggest code snippets and complete lines of code.\n",
      "* **Amazon CodeWhisperer:**  Similar to Copilot, offering AI-powered code suggestions.\n",
      "* **Tabnine:** Another AI code completion tool.\n",
      "* **Specialized Engineering AI Platforms:**  Several startups are developing LLM-powered tools tailored to specific engineering domains.\n",
      "\n",
      "**Important Considerations & Limitations:**\n",
      "\n",
      "* **Accuracy & Verification:** LLMs can hallucinate or provide inaccurate information. *Always* verify the output with established engineering principles and data.  Treat LLM output as a starting point, not a definitive answer.\n",
      "* **Domain Expertise:** LLMs lack true engineering understanding. They are pattern-matching machines, not experts.\n",
      "* **Data Dependency:**  Their performance depends heavily on the quality and quantity of training data.\n",
      "* **Bias:**  LLMs can inherit biases from their training data.\n",
      "* **Security:**  Be cautious about sharing sensitive design data with LLM-powered tools.\n",
      "\n",
      "**The Future:**\n",
      "\n",
      "LLMs are poised to become increasingly integrated into the engineering workflow.  Expect to see:\n",
      "\n",
      "* **More specialized AI tools** tailored to specific engineering disciplines.\n",
      "* **Improved accuracy and reliability** through ongoing training and development.\n",
      "* **Greater automation** of routine tasks, freeing up engineers to focus on more complex and creative problem-solving.\n",
      "* **New design paradigms** enabled by AI-driven exploration and optimization.\n",
      "\n",
      "Do you want me to delve deeper into a specific aspect, such as:\n",
      "\n",
      "*   A particular engineering discipline?\n",
      "*   A specific LLM tool?\n",
      "*   The challenges and risks associated with using LLMs in engineering?\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T09:45:19.830976Z",
     "start_time": "2025-03-16T09:44:26.146001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "class OllamaProductExtractor:\n",
    "    \"\"\"Product and price extractor using a local Ollama model\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = 'gemma3:4b'):\n",
    "        \"\"\"Initialize the Ollama-based product extractor\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.setup_database()\n",
    "\n",
    "    def adapt_datetime(dt):\n",
    "        return dt.isoformat()\n",
    "\n",
    "    def convert_datetime(bytestring):\n",
    "        return datetime.fromisoformat(bytestring.decode())\n",
    "\n",
    "    sqlite3.register_adapter(datetime, adapt_datetime)\n",
    "    sqlite3.register_converter('DATETIME', convert_datetime)\n",
    "\n",
    "    def setup_database(self):\n",
    "        \"\"\"Setup SQLite database for storing products\"\"\"\n",
    "        self.conn = sqlite3.connect('products_ollama_gemma.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS products (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            name TEXT,\n",
    "            price REAL,\n",
    "            currency TEXT,\n",
    "            source_text TEXT,\n",
    "            timestamp DATETIME\n",
    "        )\n",
    "        ''')\n",
    "        self.conn.commit()\n",
    "\n",
    "    def extract_products(self, text: str) -> list[dict[str, object]]:\n",
    "        \"\"\"Extract product names and prices from text using Ollama\"\"\"\n",
    "        system_prompt = \"\"\"\n",
    "        Extract all products and their prices mentioned in the text.\n",
    "        Return a JSON array where each item has the following format:\n",
    "        {\n",
    "            \"name\": \"Product Name\",\n",
    "            \"price\": 123.45,\n",
    "            \"currency\": \"$\"\n",
    "        }\n",
    "\n",
    "        Rules:\n",
    "        1. Extract complete product names including brand and model\n",
    "        2. Convert all prices to numeric values (no currency symbols in the price field)\n",
    "        3. Identify the currency symbol used ($, €, £, etc.) and include it separately\n",
    "        4. Return an empty array if no products with prices are detected\n",
    "        5. Do not make up any information not present in the text\n",
    "        6. Extract bangla text as well\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            response_text = response['message']['content']\n",
    "\n",
    "            # Parse the response JSON\n",
    "            try:\n",
    "                # Try direct JSON parsing\n",
    "                result = json.loads(response_text)\n",
    "\n",
    "                # Add source text to each product entry\n",
    "                for product in result:\n",
    "                    product[\"source_text\"] = text\n",
    "\n",
    "                return result\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Fallback if response isn't valid JSON - look for code blocks\n",
    "                json_match = re.search(r'```json\\s*(.*?)\\s*```', response_text, re.DOTALL)\n",
    "                if json_match:\n",
    "                    try:\n",
    "                        result = json.loads(json_match.group(1))\n",
    "                        for product in result:\n",
    "                            product[\"source_text\"] = text\n",
    "                        return result\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                print(f\"Failed to parse Ollama response as JSON: {response_text}\")\n",
    "                return []\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling Ollama API: {e}\")\n",
    "            return []\n",
    "\n",
    "    def store_products(self, products: list[dict[str, object]]):\n",
    "        \"\"\"Store extracted products in the database\"\"\"\n",
    "        for product in products:\n",
    "            self.cursor.execute(\n",
    "                \"INSERT INTO products (name, price, currency, source_text, timestamp) VALUES (?, ?, ?, ?, ?)\",\n",
    "                (product[\"name\"],\n",
    "                 product[\"price\"],\n",
    "                 product[\"currency\"],\n",
    "                 product[\"source_text\"],\n",
    "                 datetime.now())\n",
    "            )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def process_text(self, text: str) -> list[dict[str, object]]:\n",
    "        \"\"\"Process text to extract and store products\"\"\"\n",
    "        products = self.extract_products(text)\n",
    "        if products:\n",
    "            self.store_products(products)\n",
    "        return products\n",
    "\n",
    "    def process_voice(self, audio_file_path: str):\n",
    "        \"\"\"\n",
    "        Placeholder for voice processing functionality\n",
    "        In a real implementation, this would use a speech-to-text API\n",
    "        then pass the text to process_text()\n",
    "        \"\"\"\n",
    "        print(f\"Voice processing not implemented in this demo. Would process: {audio_file_path}\")\n",
    "        return []\n",
    "\n",
    "    def get_stored_products(self, limit: int = 10) -> list[dict[str, object]]:\n",
    "        \"\"\"Retrieve stored products from database\"\"\"\n",
    "        self.cursor.execute(\n",
    "            \"SELECT id, name, price, currency, source_text, timestamp FROM products ORDER BY timestamp DESC LIMIT ?\",\n",
    "            (limit,)\n",
    "        )\n",
    "        columns = [\"id\", \"name\", \"price\", \"currency\", \"source_text\", \"timestamp\"]\n",
    "        return [dict(zip(columns, row)) for row in self.cursor.fetchall()]\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close database connection\"\"\"\n",
    "        self.conn.close()\n",
    "\n",
    "\n",
    "# Demo usage\n",
    "def run_ollama_demo():\n",
    "    # Initialize the extractor\n",
    "    try:\n",
    "        extractor = OllamaProductExtractor()\n",
    "\n",
    "        # Sample texts\n",
    "        sample_texts = [\n",
    "            \"amare 5kg chal den 1000 taka\",\n",
    "            \"I bought a Samsung Galaxy S23 for $999 and AirPods Pro for $249\"\n",
    "        ]\n",
    "\n",
    "        # Process each sample text\n",
    "        all_products = []\n",
    "        for text in sample_texts:\n",
    "            print(f\"\\nProcessing text: {text}\")\n",
    "            products = extractor.process_text(text)\n",
    "            all_products.extend(products)\n",
    "            print(f\"Extracted products: {json.dumps(products, indent=2)}\")\n",
    "\n",
    "        # Show all stored products\n",
    "        stored_products = extractor.get_stored_products()\n",
    "        print(\"\\nStored products in database:\")\n",
    "        for product in stored_products:\n",
    "            print(\n",
    "                f\"ID: {product['id']} | {product['name']} - {product['currency']}{product['price']} | Source: '{product['source_text'][:30]}...'\")\n",
    "\n",
    "        # Close the connection\n",
    "        extractor.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure you have Ollama installed and running with the appropriate model.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_ollama_demo()"
   ],
   "id": "78a72e93015d6afe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing text: amare 5kg chal den 1000 taka\n",
      "Extracted products: [\n",
      "  {\n",
      "    \"name\": \"5kg chal\",\n",
      "    \"price\": 1000.0,\n",
      "    \"currency\": \"\\u09f3\",\n",
      "    \"source_text\": \"amare 5kg chal den 1000 taka\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Processing text: I bought a Samsung Galaxy S23 for $999 and AirPods Pro for $249\n",
      "Extracted products: [\n",
      "  {\n",
      "    \"name\": \"Samsung Galaxy S23\",\n",
      "    \"price\": 999.0,\n",
      "    \"currency\": \"$\",\n",
      "    \"source_text\": \"I bought a Samsung Galaxy S23 for $999 and AirPods Pro for $249\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"AirPods Pro\",\n",
      "    \"price\": 249.0,\n",
      "    \"currency\": \"$\",\n",
      "    \"source_text\": \"I bought a Samsung Galaxy S23 for $999 and AirPods Pro for $249\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Stored products in database:\n",
      "ID: 3 | AirPods Pro - $249.0 | Source: 'I bought a Samsung Galaxy S23 ...'\n",
      "ID: 2 | Samsung Galaxy S23 - $999.0 | Source: 'I bought a Samsung Galaxy S23 ...'\n",
      "ID: 1 | 5kg chal - ৳1000.0 | Source: 'amare 5kg chal den 1000 taka...'\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Deepseek",
   "id": "955fca6f550baae9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T09:43:40.099066Z",
     "start_time": "2025-03-16T09:41:15.068305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "class OllamaProductExtractor:\n",
    "    \"\"\"Product and price extractor using a local Ollama model\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = 'deepseek-r1:1.5b'):\n",
    "        \"\"\"Initialize the Ollama-based product extractor\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.setup_database()\n",
    "\n",
    "    def adapt_datetime(dt):\n",
    "        return dt.isoformat()\n",
    "\n",
    "    def convert_datetime(bytestring):\n",
    "        return datetime.fromisoformat(bytestring.decode())\n",
    "\n",
    "    sqlite3.register_adapter(datetime, adapt_datetime)\n",
    "    sqlite3.register_converter('DATETIME', convert_datetime)\n",
    "\n",
    "    def setup_database(self):\n",
    "        \"\"\"Setup SQLite database for storing products\"\"\"\n",
    "        self.conn = sqlite3.connect('products_ollama_deepseek.db', detect_types=sqlite3.PARSE_DECLTYPES)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS products (\n",
    "            id INTEGER PRIMARY KEY,\n",
    "            name TEXT,\n",
    "            price REAL,\n",
    "            currency TEXT,\n",
    "            source_text TEXT,\n",
    "            timestamp DATETIME\n",
    "        )\n",
    "        ''')\n",
    "        self.conn.commit()\n",
    "\n",
    "    def extract_products(self, text: str) -> list[dict[str, object]]:\n",
    "        \"\"\"Extract product names and prices from text using Ollama\"\"\"\n",
    "        system_prompt = \"\"\"\n",
    "        Extract all products and their prices mentioned in the text.\n",
    "        Return a JSON array where each item has the following format:\n",
    "        {\n",
    "            \"name\": \"Product Name\",\n",
    "            \"price\": 123.45,\n",
    "            \"currency\": \"$\"\n",
    "        }\n",
    "\n",
    "        Rules:\n",
    "        1. Extract complete product names including brand and model\n",
    "        2. Convert all prices to numeric values (no currency symbols in the price field)\n",
    "        3. Identify the currency symbol used ($, €, £, etc.) and include it separately\n",
    "        4. Return an empty array if no products with prices are detected\n",
    "        5. Do not make up any information not present in the text\n",
    "        6. Extract bangla text as well\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            response_text = response['message']['content']\n",
    "\n",
    "            # Parse the response JSON\n",
    "            try:\n",
    "                # Try direct JSON parsing\n",
    "                result = json.loads(response_text)\n",
    "\n",
    "                # Add source text to each product entry\n",
    "                for product in result:\n",
    "                    product[\"source_text\"] = text\n",
    "\n",
    "                return result\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # Fallback if response isn't valid JSON - look for code blocks\n",
    "                json_match = re.search(r'```json\\s*(.*?)\\s*```', response_text, re.DOTALL)\n",
    "                if json_match:\n",
    "                    try:\n",
    "                        result = json.loads(json_match.group(1))\n",
    "                        for product in result:\n",
    "                            product[\"source_text\"] = text\n",
    "                        return result\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                print(f\"Failed to parse Ollama response as JSON: {response_text}\")\n",
    "                return []\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling Ollama API: {e}\")\n",
    "            return []\n",
    "\n",
    "    def store_products(self, products: list[dict[str, object]]):\n",
    "        \"\"\"Store extracted products in the database\"\"\"\n",
    "        for product in products:\n",
    "            self.cursor.execute(\n",
    "                \"INSERT INTO products (name, price, currency, source_text, timestamp) VALUES (?, ?, ?, ?, ?)\",\n",
    "                (product[\"name\"],\n",
    "                 product[\"price\"],\n",
    "                 product[\"currency\"],\n",
    "                 product[\"source_text\"],\n",
    "                 datetime.now())\n",
    "            )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def process_text(self, text: str) -> list[dict[str, object]]:\n",
    "        \"\"\"Process text to extract and store products\"\"\"\n",
    "        products = self.extract_products(text)\n",
    "        if products:\n",
    "            self.store_products(products)\n",
    "        return products\n",
    "\n",
    "    def process_voice(self, audio_file_path: str):\n",
    "        \"\"\"\n",
    "        Placeholder for voice processing functionality\n",
    "        In a real implementation, this would use a speech-to-text API\n",
    "        then pass the text to process_text()\n",
    "        \"\"\"\n",
    "        print(f\"Voice processing not implemented in this demo. Would process: {audio_file_path}\")\n",
    "        return []\n",
    "\n",
    "    def get_stored_products(self, limit: int = 10) -> list[dict[str, object]]:\n",
    "        \"\"\"Retrieve stored products from database\"\"\"\n",
    "        self.cursor.execute(\n",
    "            \"SELECT id, name, price, currency, source_text, timestamp FROM products ORDER BY timestamp DESC LIMIT ?\",\n",
    "            (limit,)\n",
    "        )\n",
    "        columns = [\"id\", \"name\", \"price\", \"currency\", \"source_text\", \"timestamp\"]\n",
    "        return [dict(zip(columns, row)) for row in self.cursor.fetchall()]\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close database connection\"\"\"\n",
    "        self.conn.close()\n",
    "\n",
    "\n",
    "# Demo usage\n",
    "def run_ollama_demo():\n",
    "    # Initialize the extractor\n",
    "    try:\n",
    "        extractor = OllamaProductExtractor()\n",
    "\n",
    "        # Sample texts\n",
    "        sample_texts = [\n",
    "            \"amare 5kg chal den 1000 taka\",\n",
    "            \"I bought a Samsung Galaxy S23 for $999 and AirPods Pro for $249\"\n",
    "        ]\n",
    "\n",
    "        # Process each sample text\n",
    "        all_products = []\n",
    "        for text in sample_texts:\n",
    "            print(f\"\\nProcessing text: {text}\")\n",
    "            products = extractor.process_text(text)\n",
    "            all_products.extend(products)\n",
    "            print(f\"Extracted products: {json.dumps(products, indent=2)}\")\n",
    "\n",
    "        # Show all stored products\n",
    "        stored_products = extractor.get_stored_products()\n",
    "        print(\"\\nStored products in database:\")\n",
    "        for product in stored_products:\n",
    "            print(\n",
    "                f\"ID: {product['id']} | {product['name']} - {product['currency']}{product['price']} | Source: '{product['source_text'][:30]}...'\")\n",
    "\n",
    "        # Close the connection\n",
    "        extractor.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure you have Ollama installed and running with the appropriate model.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_ollama_demo()"
   ],
   "id": "4e829aba0e26ac0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing text: amare 5kg chal den 1000 taka\n",
      "Failed to parse Ollama response as JSON: <think>\n",
      "Alright, let me try to figure out how to approach this problem. So, the user has given a query where they want all products and their prices extracted in a specific JSON format. They also mentioned that the text includes bangla (Assam) content, so I need to make sure that my solution is both accurate and language-agnostic.\n",
      "\n",
      "First, I'll break down the requirements. The output should be an array of objects, each containing \"name\", \"price\", and \"currency\". The price needs to be converted into a numeric format without any currency symbols, but the currency itself must be included as part of the object. If no products are found, it should return an empty array.\n",
      "\n",
      "Looking at the example provided: \"amare 5kg chal den 1000 taka\". I notice that this is in Bangla. The name here is \"5kg chal\" and the price is \"1000 taka\". So, my solution needs to handle different languages correctly.\n",
      "\n",
      "I'll start by parsing the input text. Since it's possibly a webpage or a similar content source, I might need to extract all products, even if they're hidden. But for this task, maybe extracting from a specific section is enough? Alternatively, perhaps extracting all visible products would be better. However, without knowing exactly where to look, I'll assume that the user wants the products in the given text.\n",
      "\n",
      "Next, I need to identify all product names and prices within the text. For each product name, I must extract both the brand name (like \"amare\") and the model (\"5kg chal\"). The price needs to be converted from the local currency symbol (taka) to a numeric value without the symbol.\n",
      "\n",
      "I also need to ensure that my solution is robust enough to handle different languages. That means checking for currency symbols in products like \"€\" or \"£\", which aren't part of any product names.\n",
      "\n",
      "Now, thinking about how to structure this in JavaScript. I'll need an array to hold the results. For each product found:\n",
      "\n",
      "- Extract the name: Combine the brand (starting with 'amare') and the model.\n",
      "- Determine if there's a price symbol. If present, check its value; otherwise, assume it's without any currency symbol, so no conversion is needed.\n",
      "- Convert the price to a number by removing the currency symbol.\n",
      "\n",
      "Wait, but in the example, \"1000 taka\" becomes 1000. So I need to ensure that if there's no currency symbol, the price is treated as a numeric string.\n",
      "\n",
      "I also have to be careful with locale-specific number formatting. For instance, in some locales, the comma is used instead of the decimal point for numbers less than one. But in this case, since we're dealing with products and prices without fractions or decimals, it's probably safe to assume that each price is a standard number without any commas.\n",
      "\n",
      "Putting it all together, I'll write code that:\n",
      "\n",
      "1. Iterates through all products in the text.\n",
      "2. For each product name, extract brand and model.\n",
      "3. Check if there's a price symbol (taka, £, etc.) and convert to numeric value.\n",
      "4. Create an object with \"name\", \"price\" as a number, and \"currency\".\n",
      "5. Collect all such objects into an array.\n",
      "\n",
      "I'll need to handle cases where no products are found, returning an empty array instead of null or undefined. Also, I should ensure that the currency is correctly identified regardless of language.\n",
      "\n",
      "Potential issues include:\n",
      "\n",
      "- Incorrect parsing of prices: Not sure how the price is formatted. But since it's supposed to be numeric, maybe just converting by removing symbols works.\n",
      "- Language-specific characters in product names: The brand might have a space or other symbols, but \"amare\" followed by a space should work as the name starts with that.\n",
      "\n",
      "Testing this logic with the example given:\n",
      "\n",
      "Input text: \"amare 5kg chal den 1000 taka\"\n",
      "\n",
      "Extracted product:\n",
      "- Name: \"5kg chal\"\n",
      "- Price: \"1000\", converted to 1000.\n",
      "- Currency: \"taka\"\n",
      "\n",
      "So the output should be an object with these properties.\n",
      "\n",
      "I think this approach covers all bases. Now, I'll structure the code accordingly, making sure to handle edge cases like empty strings or no products found.\n",
      "</think>\n",
      "\n",
      "To solve this problem, we need to extract complete product names and their prices from a given text, convert the prices into numeric values without currency symbols, identify the currency used, and return the results in a specific JSON format. If no products are found, the function should return an empty array.\n",
      "\n",
      "### Approach\n",
      "1. **Extract Product Names**: Extract both the brand name (starting with \"amare\") and the product model from the text.\n",
      "2. **Identify Currency Symbol**: Check for any currency symbol ($, €, £, etc.) present in the product names or prices to identify the used currency.\n",
      "3. **Convert Prices**: Convert the price values from their respective currency symbols into numeric values (without the currency symbol).\n",
      "4. **Create JSON Objects**: For each extracted product, create an object with \"name\", \"price\" as a number, and \"currency\".\n",
      "5. **Handle Edge Cases**: If no products are found, return an empty array.\n",
      "\n",
      "### Solution Code\n",
      "```javascript\n",
      "function extractProductsAndPrices(text) {\n",
      "    const results = [];\n",
      "    // Split the text into lines based on newlines\n",
      "    const lines = text.split('\\n').filter(line => line.trim());\n",
      "    \n",
      "    for (const line of lines) {\n",
      "        const productInfo = line.match(/(\\S+)\\s*(\\d+) taka|\\S+/g);\n",
      "        \n",
      "        if (productInfo) {\n",
      "            // Extract name: brand and model\n",
      "            const nameMatch = productInfo[1];\n",
      "            const priceMatch = productInfo[2];\n",
      "            \n",
      "            // Extract name as \"Brand Model\"\n",
      "            const productName = `${nameMatch.charAt(0)} amare` + (nameMatch.length > 1 ? nameMatch.slice(1) : '');\n",
      "            \n",
      "            // Determine currency\n",
      "            let currency;\n",
      "            if (priceMatch === 'taka') {\n",
      "                currency = 'taka';\n",
      "            } else if (priceMatch === '£' || priceMatch === '€') {\n",
      "                currency = `${priceMatch}'`;\n",
      "            }\n",
      "\n",
      "            // Convert price to numeric value\n",
      "            const price = parseInt(priceMatch.replace(/[^0-9]/g, ''), 10);\n",
      "            \n",
      "            // Create and add object to results array\n",
      "            results.push({\n",
      "                name: productName,\n",
      "                price: parseFloat(price),\n",
      "                currency: currency\n",
      "            });\n",
      "        }\n",
      "    }\n",
      "    \n",
      "    return results;\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation\n",
      "- **Extract Product Names**: The function splits the text into lines and uses regular expressions to extract product names, which include both the brand (\"amare\") and the model (e.g., \"5kg chal\").\n",
      "- **Identify Currency Symbol**: Regular expressions are used to check for presence of currency symbols in the text.\n",
      "- **Convert Prices**: The price values are converted from their respective currency symbols into numeric strings using `parseInt`.\n",
      "- **Create JSON Objects**: Each product object is created with the name, price as a number, and the identified currency. These objects are collected into an array which is returned at the end.\n",
      "\n",
      "This approach ensures that all products are accurately extracted, their names are correctly formatted, and their prices are accurately converted into numeric values while preserving the original currency information.\n",
      "Extracted products: []\n",
      "\n",
      "Processing text: I bought a Samsung Galaxy S23 for $999 and AirPods Pro for $249\n",
      "Extracted products: [\n",
      "  {\n",
      "    \"name\": \"Samsung Galaxy S23\",\n",
      "    \"price\": 999,\n",
      "    \"currency\": \"$\",\n",
      "    \"source_text\": \"I bought a Samsung Galaxy S23 for $999 and AirPods Pro for $249\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"AirPods Pro\",\n",
      "    \"price\": 249,\n",
      "    \"currency\": \"$\",\n",
      "    \"source_text\": \"I bought a Samsung Galaxy S23 for $999 and AirPods Pro for $249\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Stored products in database:\n",
      "ID: 2 | AirPods Pro - $249.0 | Source: 'I bought a Samsung Galaxy S23 ...'\n",
      "ID: 1 | Samsung Galaxy S23 - $999.0 | Source: 'I bought a Samsung Galaxy S23 ...'\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
